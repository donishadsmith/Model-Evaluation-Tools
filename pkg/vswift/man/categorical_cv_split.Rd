% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/categorical_cv_split.R
\name{categorical_cv_split}
\alias{categorical_cv_split}
\title{Perform Train-Test Split and/or K-Fold Cross-Validation for Classification Data}
\usage{
categorical_cv_split(
  data = NULL,
  y_col = NULL,
  x_col = NULL,
  split = NULL,
  fold_n = NULL,
  model_type = NULL,
  stratified = FALSE,
  random_seed = NULL,
  remove_obs = FALSE,
  save_models = FALSE,
  save_data = FALSE,
  ...
)
}
\arguments{
\item{data}{A data frame containing the dataset.}

\item{y_col}{The response variable's numerical index or name in the data frame.}

\item{x_col}{A vector of numerical indices or names for the features in the data frame.
If not specified, all variables except the response variable will be used as features.}

\item{split}{A number between 0.5 and 0.9 for the proportion of data to use for the training set,
leaving the rest for the test set. If not specified, train-test splitting will not be done.}

\item{fold_n}{An integer between 3 and 30 for the number of folds to use. If not specified,
k-fold cross validation will not be performed.}

\item{model_type}{A character string indicating the classification algorithm to use. Available options:
"lda", "qda", "logistic", "svm", "naivebayes", "ann", "knn", "decisiontree", "randomforest".
For "knn", the optimal k will be used unless specified with `ks =`.
For "ann", `size =` must be specified as an additional argument.}

\item{stratified}{A logical value indicating if stratified sampling should be used. Default = FALSE.}

\item{random_seed}{A numerical value for the random seed. Default is NULL.}

\item{remove_obs}{A logical value to remove observations with categorical features from the test/validation set
that have not been observed during model training. Some algorithms may produce an error if this occurs. Default is FALSE.}

\item{save_models}{A logical value to save models during train-test splitting and/or k-fold cross validation. Default is FALSE.}

\item{save_data}{A logical value to save all training and test/validation sets during train-test splitting and/or k-fold cross validation. Default is FALSE.}

\item{...}{Additional arguments specific to the chosen classification algorithm.
Please refer to the corresponding algorithm's documentation for additional arguments and their descriptions.}
}
\value{
A list containing the results of train-test splitting and/or k-fold cross-validation,
        including performance metrics, information on the class distribution in the training, test sets, and folds (if applicable), 
        saved models (if specified), and saved datasets (if specified).
}
\description{
`categorical_cv_split` performs a train-test split and/or k-fold cross validation
on classification data using various classification algorithms.
}
\section{Model-specific additional arguments}{

  Each model type accepts additional arguments specific to the classification algorithm. The available arguments for each model type are:

  - "lda": grouping, prior, method, nu
  - "qda": grouping, prior, method, nu
  - "logistic": weights, start, etastart, mustart, offset, control, contrasts, intercept, singular.ok, type
  - "svm": scale, type, kernel, degree, gamma, coef0, cost, nu, class.weights, cachesize, tolerance, epsilon, shrinking, cross, probability, fitted
  - "naivebayes": prior, laplace, usekernel, usepoisson
  - "ann": weights, size, Wts, mask, linout, entropy, softmax, censored, skip, rang, decay, maxit, Hess, trace, MaxNWts, abstol, reltol
  - "knn": kmax, ks, distance, kernel, scale, contrasts, ykernel
  - "decisiontree": weights, method, parms, control, cost
  - "randomforest": ntree, mtry, weights, replace, classwt, cutoff, strata, nodesize, maxnodes, importance, localImp, nPerm, proximity, oob.prox, norm.votes, do.trace, keep.forest, corr.bias, keep.inbag
}

\section{Functions used from packages for each model type}{


  - "lda": lda() from MASS package
  - "qda": qda() from MASS package
  - "logistic": glm() from base package with family = "binomial"
  - "svm": svm() from e1071 package
  - "naivebayes": naive_bayes() from naivebayes package
  - "ann": nnet() from nnet package
  - "knn": train.kknn() from kknn package
  - "decisiontree": rpart() from rpart package
  - "randomforest": randomForest() from randomForest package
}

\examples{
# Load an example dataset
data(iris)

# Perform a train-test split with an 80\% training set using LDA
result <- categorical_cv_split(iris, y_col = "Species", split = 0.8, model_type = "lda")

# Perform 5-fold cross-validation using QDA
result <- categorical_cv_split(iris, y_col = "Species", fold_n = 5, model_type = "qda")
}
\seealso{
\code{\link{print.vswift}}, \code{\link{plot.vswift}}
}
